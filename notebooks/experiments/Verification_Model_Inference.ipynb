{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Verification-Model-Inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries"
      ],
      "metadata": {
        "id": "dsI5alLc_925"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZacGV27v_zOQ",
        "outputId": "3ad75a24-419a-4d0c-ba26-f1b736c920b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'model_path':'/gdrive/MyDrive/arman/verification-models/neural_net2.pth',\n",
        "    'voice_sample1':'/content/sample1.wav',\n",
        "    'voice_sample2':'/content/sample2.wav',\n",
        "}"
      ],
      "metadata": {
        "id": "C4FjQZW9BNEE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wave\n",
        "!pip install ffmpeg-python\n",
        "!pip install speechbrain\n",
        "!pip install torchaudio\n",
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb9OnQ3yACfW",
        "outputId": "4253cafd-b959-4710-85d5-e96128842610"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wave\n",
            "  Downloading Wave-0.0.2.zip (38 kB)\n",
            "Building wheels for collected packages: wave\n",
            "  Building wheel for wave (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wave: filename=Wave-0.0.2-py3-none-any.whl size=1240 sha256=16d62300c2088c919edb3bcbcdaef14adde657584f98c198a0891510d10041ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/e8/fe/458c7dac00c6abedad6380b9d0ef1a5cbc7c21807df1d30915\n",
            "Successfully built wave\n",
            "Installing collected packages: wave\n",
            "Successfully installed wave-0.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting speechbrain\n",
            "  Downloading speechbrain-0.5.11-py3-none-any.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.1.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.4.1)\n",
            "Collecting hyperpyyaml\n",
            "  Downloading HyperPyYAML-1.0.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from speechbrain) (0.11.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from speechbrain) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.21.6)\n",
            "Requirement already satisfied: torch<=1.11,>=1.7 in /usr/local/lib/python3.7/dist-packages (from speechbrain) (1.11.0+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from speechbrain) (21.3)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.11,>=1.7->speechbrain) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (3.7.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->speechbrain) (4.11.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->speechbrain) (3.0.9)\n",
            "Collecting ruamel.yaml>=0.17.8\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 51.0 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub->speechbrain) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub->speechbrain) (1.24.3)\n",
            "Building wheels for collected packages: hyperpyyaml\n",
            "  Building wheel for hyperpyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hyperpyyaml: filename=HyperPyYAML-1.0.1-py3-none-any.whl size=15192 sha256=785d3b92e84923d158fd316ca9fc4fe55633f147c482bf985c85a733f8c0d8a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/87/65/266d722c3932f81f16332ce842e972be8421e3a9cd3771766b\n",
            "Successfully built hyperpyyaml\n",
            "Installing collected packages: ruamel.yaml.clib, ruamel.yaml, pyyaml, sentencepiece, hyperpyyaml, huggingface-hub, speechbrain\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 hyperpyyaml-1.0.1 pyyaml-6.0 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 sentencepiece-0.1.96 speechbrain-0.5.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.11.0+cu113)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchaudio) (4.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from speechbrain.lobes.augment import EnvCorrupt\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from torch import nn\n",
        "import speechbrain as sb\n",
        "import torchaudio\n",
        "from speechbrain.pretrained import SpectralMaskEnhancement\n",
        "from speechbrain.pretrained import SpeakerRecognition\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import json\n",
        "import random\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from difflib import get_close_matches\n",
        "import io\n",
        "import scipy\n",
        "import ffmpeg\n",
        "import wave\n",
        "import os\n",
        "import numpy as np\n",
        "import IPython.display as ipd\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "tgkPITupARwK"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wNquMajvRmuC"
      },
      "outputs": [],
      "source": [
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Models"
      ],
      "metadata": {
        "id": "vcPE3Ee-Ae1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeakerVerification(SpeakerRecognition):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.similarity = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
        "\n",
        "    @classmethod\n",
        "    def from_hparams(cls, *args, **kwargs):\n",
        "        verification = super(cls,cls).from_hparams(*args, **kwargs)\n",
        "        source = kwargs['source']\n",
        "        if os.path.exists(os.path.join(source, 'imposter_embeddings.pt')):\n",
        "            verification.imp_emb = torch.load(os.path.join(source, 'imposter_embeddings.pt'))\n",
        "        \n",
        "        return verification\n",
        "    \n",
        "    def compute_snorm(self, emb1, emb2):\n",
        "        emb1 = emb1.squeeze(0)\n",
        "        emb2 = emb2.squeeze(0)\n",
        "        score_e1 = self.similarity(emb1, self.imp_emb)\n",
        "        score_e2 = self.similarity(emb1, self.imp_emb)\n",
        "        score_e1_e2 = self.similarity(emb1, emb2)\n",
        "        score_e1_normed = (score_e1_e2 - score_e1.mean()) / score_e1.std()\n",
        "        score_e2_normed = (score_e1_e2 - score_e2.mean()) / score_e2.std()\n",
        "        return score_e1_normed + score_e2_normed\n",
        "          \n",
        "    def verify_files(self, path_x, path_y, threshold=0.25, mean_norm=True, snorm=True):\n",
        "        \"\"\"Speaker verification with cosine distance\n",
        "        Returns the score and the decision (0 different speakers,\n",
        "        1 same speakers).\n",
        "        Returns\n",
        "        -------\n",
        "        score\n",
        "            The score associated to the binary verification output\n",
        "            (cosine distance).\n",
        "        prediction\n",
        "            The prediction is 1 if the two signals in input are from the same\n",
        "            speaker and 0 otherwise.\n",
        "        \"\"\"\n",
        "        batch_x, _ = torchaudio.load(path_x)\n",
        "        batch_y, _ = torchaudio.load(path_y)\n",
        "        # Verify:\n",
        "        emb1 = self.encode_batch(batch_x, normalize=mean_norm)\n",
        "        emb2 = self.encode_batch(batch_y, normalize=mean_norm)\n",
        "        # SNorm\n",
        "        if snorm and hasattr(self, 'imp_emb'):\n",
        "            score = self.compute_snorm(emb1, emb2)\n",
        "        else:\n",
        "            score = self.similarity(emb1, emb2)\n",
        "        decision = score > threshold\n",
        "        # Squeeze:\n",
        "        return score[0], decision[0]\n",
        "    def get_output_embeddings(self, path_x, path_y, threshold=0.25, mean_norm=True, snorm=True):\n",
        "        batch_x, _ = torchaudio.load(path_x)\n",
        "        batch_y, _ = torchaudio.load(path_y)\n",
        "        # Verify:\n",
        "        emb1 = self.encode_batch(batch_x, normalize=mean_norm)\n",
        "        emb2 = self.encode_batch(batch_y, normalize=mean_norm)\n",
        "        return emb1, emb2\n",
        "    def get_speaker_vector(self, path_x, mean_norm=True, snorm=True):\n",
        "        batch_x, _ = torchaudio.load(path_x)\n",
        "        embedding = self.encode_batch(batch_x, normalize=mean_norm)[0][0].numpy()\n",
        "        return embedding\n",
        "    def get_input_vector(self, path_x, mean_norm=True, snorm=True):\n",
        "        batch_x, _ = torchaudio.load(path_x)\n",
        "        return batch_x.numpy()[0]"
      ],
      "metadata": {
        "id": "3GbBuuMIo7VP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/temp_verification_model/\n",
        "!mkdir /content/temp_verification_model/\n",
        "!cp -r /gdrive/MyDrive/shared_space/ecapa-tdnn/* /content/temp_verification_model/"
      ],
      "metadata": {
        "id": "tMb_bJhCqVdP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: This needs a GPU!\n",
        "verification_model = SpeakerVerification.from_hparams(source=\"/content/temp_verification_model/\", hparams_file='hparams_inference.yaml', savedir=\"/tmp\")"
      ],
      "metadata": {
        "id": "xWKUlWjnphCb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class my_neural_net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(my_neural_net, self).__init__() \n",
        "        self.flatten = torch.nn.Flatten()\n",
        "        self.first_layer = torch.nn.Sequential( \n",
        "            nn.Linear(2*192, 192),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(192, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        output = self.first_layer(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "8LM16ozFA-7X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = my_neural_net()\n",
        "model.load_state_dict(torch.load(config['model_path']))\n",
        "model.eval() # use this line if you have Dropout and BatchNormalization layers in your model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_lldL9oAtQ7",
        "outputId": "fb191072-849b-42e5-cea4-2002b53f96ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "my_neural_net(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (first_layer): Sequential(\n",
              "    (0): Linear(in_features=384, out_features=192, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=192, out_features=1, bias=True)\n",
              "    (3): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_pair(path1, path2):\n",
        "  vec1 = verification_model.get_speaker_vector(path1)\n",
        "  vec2 = verification_model.get_speaker_vector(path2)\n",
        "  features = np.array([vec1, vec2]).reshape(1, 2, 192)\n",
        "  output = model(torch.from_numpy(features).to(torch.float32))\n",
        "  output = output.detach().squeeze().numpy()\n",
        "  num_speakers = 1 if abs(output-1) < abs(output) else 2\n",
        "  return f'the voices belong to {num_speakers} speaker(s) - score: {output}'"
      ],
      "metadata": {
        "id": "18jZ0V_XCxLh"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_vectors(vec1, vec2):\n",
        "  features = np.array([vec1, vec2]).reshape(1, 2, 192)\n",
        "  output = model(torch.from_numpy(features).to(torch.float32))\n",
        "  output = output.detach().squeeze().numpy()\n",
        "  output = 1 if abs(output-1) < abs(output) else 0\n",
        "  return output"
      ],
      "metadata": {
        "id": "cpLih_PuJO2b"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhfLDPM9RgZy"
      },
      "source": [
        "#Recording an audio file using the current device's microphone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio, sr = get_audio()\n",
        "scipy.io.wavfile.write(config['voice_sample1'],sr, audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "id": "2IGtNI4jMBDf",
        "outputId": "3155be67-b366-4d44-ec60-d50b31168bab"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio, sr = get_audio()\n",
        "scipy.io.wavfile.write(config['voice_sample2'],sr, audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "id": "0IiiGPj0DquB",
        "outputId": "f7212c7f-0d26-44c0-fce8-d00f94afd248"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verify_pair(config['voice_sample1'], config['voice_sample2'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ILQZPXKUD49M",
        "outputId": "154ae249-df42-4470-eba3-72124b872c26"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the voices belong to 1 speaker(s) - score: 1.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on our own data"
      ],
      "metadata": {
        "id": "ccfn3ApfHVpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_file_names = [str(i)+'.wav' for i in range(1,26)]\n",
        "list_of_file_names.extend(['26-1.wav','26-2.wav','26-3.wav','26-4.wav','26-5.wav'])\n",
        "list_of_file_names.extend([str(i)+'.wav' for i in range(27, 41)])"
      ],
      "metadata": {
        "id": "CS9M8fP5HajX"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_speakers = ['amirinezhad','chavoshi','dehghanmonfared','dehghanpoor','hosseini','jafarpisheh',\n",
        "                    'maghsoodloo','malekzadeh','ramezani','razavi','shayanfar']\n",
        "list_of_speakers.extend(['woman'+str(i) for i in range(1, 10)])"
      ],
      "metadata": {
        "id": "M48IWWi5HjB9"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_path = '/gdrive/MyDrive/shared_space/car-commands/'\n",
        "vectors = []\n",
        "labels = []\n",
        "for speaker in list_of_speakers:\n",
        "  for file_name in list_of_file_names:\n",
        "    file_path = f'{our_path}/{speaker}/{file_name}'\n",
        "    curr_out = verification_model.get_speaker_vector(file_path)\n",
        "    vectors.append(curr_out)\n",
        "    labels.append(speaker)"
      ],
      "metadata": {
        "id": "8zNN4ouzHkQS"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhzZ3bWCKGVY",
        "outputId": "7036d43f-5b0c-4f67-8e35-2f141a671ba3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "880"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[550]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "csliOETyPz9S",
        "outputId": "2624db36-d0f9-4859-dc9e-b322de74e918"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'woman2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "person_counter = Counter()\n",
        "idx_counter = Counter()\n",
        "num_iterations = 0\n",
        "unique_men = set()\n",
        "unique_women = set()\n",
        "pos_counter = 0\n",
        "neg_counter = 0\n",
        "\n",
        "pair_vectors = []\n",
        "pair_labels = []\n",
        "\n",
        "while num_iterations <= 100000:\n",
        "  num_iterations += 1\n",
        "  print(f'\\r iter:{num_iterations}, {len(unique_men)} u-men, {len(unique_women)} u-women, {pos_counter} pos, {neg_counter} neg', end=' ')\n",
        "\n",
        "  idx1, idx2 = random.sample([i for i in range(880)], 2)\n",
        "  person1 = labels[idx1]\n",
        "  gender1 = 'female' if person1.startswith('woman') else 'male'\n",
        "\n",
        "  if person_counter[person1] >= 20:\n",
        "    continue\n",
        "  if gender1 == 'male' and len(unique_women)>0 and len(unique_men)/len(unique_women) > 1.5:\n",
        "    continue\n",
        "  if gender1 == 'female' and len(unique_men)>0 and len(unique_women)/len(unique_men) > 1.5:\n",
        "    continue\n",
        "\n",
        "  person2 = labels[idx2]\n",
        "  gender2 = 'female' if person1.startswith('woman') else 'male'\n",
        "\n",
        "  if person_counter[person2] >= 20:\n",
        "    continue\n",
        "  if gender1 == 'male' and len(unique_women)>0 and len(unique_men)/len(unique_women) > 1.5:\n",
        "    continue\n",
        "  if gender1 == 'female' and len(unique_men)>0 and len(unique_women)/len(unique_men) > 1.5:\n",
        "    continue\n",
        "\n",
        "  if person1 == person2 and neg_counter > 0 and pos_counter / neg_counter > 1.5:\n",
        "    continue\n",
        "  if person1 != person2 and pos_counter > 0 and neg_counter / pos_counter > 1.5:\n",
        "    continue\n",
        "\n",
        "  # if everything is ok\n",
        "\n",
        "  if gender1 == 'male':\n",
        "    unique_men.add(person1)\n",
        "  else:\n",
        "    unique_women.add(person1)\n",
        "  if gender2 == 'male':\n",
        "    unique_men.add(person2)\n",
        "  else:\n",
        "    unique_women.add(person2)\n",
        "\n",
        "  if person1 == person2:\n",
        "    pos_counter += 1\n",
        "  else:\n",
        "    neg_counter += 1\n",
        "\n",
        "  pair_vectors.append([vectors[idx1], vectors[idx2]])\n",
        "  pair_labels.append(0 if person1 != person2 else 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETvWCbghHrdk",
        "outputId": "bcd2215f-4a7a-4590-a961-3517c1d6d8ed"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " iter:100001, 20 u-men, 20 u-women, 4918 pos, 7378 neg "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_labels = [verify_vectors(pair[0], pair[1]) for pair in pair_vectors]"
      ],
      "metadata": {
        "id": "WG9MdTjJRuO-"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = sum([1 if true == pred else 0 for true, pred in zip(pair_labels, pred_labels)])/len(pair_labels)"
      ],
      "metadata": {
        "id": "NPTQXFAtSArA"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy on our own dataset : {accuracy*100} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "513slvhTSOPv",
        "outputId": "0db13bf3-2bb0-43fe-e7e2-6e37c9fb55e2"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on our own dataset : 82.31945348080677 %\n"
          ]
        }
      ]
    }
  ]
}